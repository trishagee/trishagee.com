{
 "disqus_url" : "http://trishagee.github.io/post/dissecting_the_disruptor_why_its_so_fast_part_one__locks_are_bad/",
 "disqus_title" : "Dissecting the Disruptor: Why it's so fast (part one) - Locks Are Bad",
 "Title": "Dissecting the Disruptor: Why it's so fast (part one) - Locks Are Bad",
 "Pubdate": "2011-07-16",
 "Slug": "dissecting_the_disruptor_why_its_so_fast_part_one__locks_are_bad",
 "Section": "post"
}
Martin Fowler has written a <a href="http://martinfowler.com/articles/lmax.html"><span id="goog_1736243820"></span>really good article<span id="goog_1736243821"></span></a> describing not only <a href="http://code.google.com/p/disruptor/">the Disruptor</a>, but also how it fits into the architecture at <a href="http://www.lmaxtrader.co.uk/">LMAX</a>. &nbsp;This gives some of the context that has been missing so far, but the most frequently asked question is still "What is the Disruptor?".<br /><br />I'm working up to answering that. &nbsp;I'm currently on question number two: "Why is it so fast?".<br /><br />These questions do go hand in hand, however, because I can't talk about why it's fast without saying what it does, and I can't talk about what it is without saying why it is that way.<br /><br />So I'm trapped in a circular dependency. &nbsp;A circular dependency of blogging.<br /><br />To break the dependency, I'm going to answer question one with the simplest answer, and with any luck I'll come back to it in a later post if it still needs explanation:&nbsp;the Disruptor is a way to pass information between threads.<br /><br />As a developer, already my alarm bells are going off because the word "thread" was just mentioned, which means this is about concurrency, and Concurrency Is Hard.<br /><br /><b>Concurrency 101</b><br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-jFd0nHVAUzA/Th6pstBr8rI/AAAAAAAAIH4/_eCHINrgH50/s1600/ThreadContention.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="231" src="http://3.bp.blogspot.com/-jFd0nHVAUzA/Th6pstBr8rI/AAAAAAAAIH4/_eCHINrgH50/s400/ThreadContention.png" width="400" /></a></div><br />Imagine two threads are trying to change the same value. <br /><br /><i>Case One:</i> Thread 1 gets there first:<br /><ol><li>The value changes to "blah"</li><li>Then the value changes to "blahy" when Thread 2 gets there.</li></ol><div><i>Case Two:</i> Thread 2 gets there first:</div><div><ol><li>The value changes to "fluffy"</li><li>Then the value changes to "blah" when Thread 1 gets there.</li></ol><div><i>Case Three:</i> Thread 1 interrupts Thread 2:</div></div><div><ol><li>Thread 2 gets the value "fluff" and stores it as <code>myValue</code></li><li>Thread 1 goes in and updates value to "blah"</li><li>Then Thread 2 wakes up and sets the value to "fluffy".</li></ol><div>Case Three is probably the only one which is definitely wrong, unless you think the naive approach to wiki editing is OK (<a href="http://code.google.com/">Google Code</a> Wiki, I'm looking at you...). &nbsp;In the other two cases it's all about intentions and predictability. &nbsp;Thread 2 might not care what's in <code>value</code>, the intention might be to append "y" to whatever is in there regardless. &nbsp;In this circumstance, cases one and two are both correct.<br /><br /></div></div><div></div><div>But if Thread 2 only wanted to change "fluff" to "fluffy", then both cases two and three are incorrect.</div><div></div><div>Assuming that Thread 2 wants to set the value to "fluffy", there are some different approaches to solving the problem.<br /><br /></div><div></div><div><b>Approach One: Pessimistic locking</b><br /><b><br /></b></div><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-2A7ebRJ1z5g/Th6t4t2AO8I/AAAAAAAAIH8/gAYXlVq86-s/s1600/ConcurrencyPessimisticLocking.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="257" src="http://4.bp.blogspot.com/-2A7ebRJ1z5g/Th6t4t2AO8I/AAAAAAAAIH8/gAYXlVq86-s/s400/ConcurrencyPessimisticLocking.png" width="400" /></a></div><div>(Does the "No Entry" sign make sense to people who don't drive in Britain?)<br /><br />The terms pessimistic and optimistic locking seem to be more commonly used when talking about database reads and writes, but the principal applies to getting a lock on an object.<br /><br /></div><div></div><div>Thread 2 grabs a lock on <code>Entry</code> as soon as it knows it needs it and stops anything from setting it. Then it does its thing, sets the value, and lets everything else carry on.<br /><br /></div><div></div><div>You can imagine this gets quite expensive, with threads hanging around all over the place trying to get hold of objects and being blocked. &nbsp;The more threads you have, the more chance that things are going to grind to a halt.<br /><br /></div><div><b>Approach Two: Optimistic locking</b></div><div class="separator" style="clear: both; text-align: center;"></div><div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-MC3Zia0u-LI/TiGrA4AEKKI/AAAAAAAAIIo/7q-x9sSJYR4/s1600/ConcurrencyOptimisticLocking.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="252" src="http://2.bp.blogspot.com/-MC3Zia0u-LI/TiGrA4AEKKI/AAAAAAAAIIo/7q-x9sSJYR4/s400/ConcurrencyOptimisticLocking.png" width="400" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"></div>In this case Thread 2 will only lock <code>Entry</code> when it needs to write to it. &nbsp;In order to make this work, it needs to check if <code>Entry</code> has changed since it first looked at it. &nbsp;If Thread 1 came in and changed the value to "blah" after Thread 2 had read the value, Thread 2 couldn't write "fluffy" to the <code>Entry</code> and trample all over the change from Thread 1. &nbsp;Thread 2 could either re-try (go back, read the value, and append "y" onto the end of the new value), which you would do if Thread 2 didn't care what the value it was changing was; or it could throw an exception or return some sort of failed update flag if it was expecting to change "fluff" to "fluffy". &nbsp;An example of this latter case might be if you have two users trying to update a Wiki page, and you tell the user on the other end of Thread 2 they'll need to load the new changes from Thread 1 and then reapply their changes.<br /><br /></div><div></div><div><b>Potential Problem: Deadlock</b></div><div>Locking can lead to all sorts of issues, for example deadlock. &nbsp;Imagine two threads that need access to two resources to do whatever they need to do:<br /><br /></div><div></div><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-sDyHhoLnwxw/Th60id1KUEI/AAAAAAAAIIE/_ru21J5fklI/s1600/ConcurrencyDeadlock.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="240" src="http://2.bp.blogspot.com/-sDyHhoLnwxw/Th60id1KUEI/AAAAAAAAIIE/_ru21J5fklI/s400/ConcurrencyDeadlock.png" width="400" /></a></div><div><br />If you've used an over-zealous locking technique, both threads are going to sit there forever waiting for the other one to release its lock on the resource. &nbsp;That's when you reboot <strike>Windows</strike> your computer.<br /><br /><b>Definite Problem: Locks are sloooow...</b><br />The thing about locks is that they need the operating system to arbitrate the argument. &nbsp;The threads are like siblings squabbling over a toy, and the OS kernel is the parent that decides which one gets it. It's like when you run to your Dad to tell him your sister has nicked the <a href="http://www.amazon.com/Transformers-Power-Bots-Optimus-Prime/dp/B003A6CK0O?ie=UTF8&amp;tag=trissramb-20&amp;link_code=btl&amp;camp=213689&amp;creative=392969" target="_blank">Transformer</a><img alt="" border="0" height="1" src="http://www.assoc-amazon.com/e/ir?t=trissramb-20&amp;l=btl&amp;camp=213689&amp;creative=392969&amp;o=1&amp;a=B003A6CK0O" style="border: none !important; margin: 0px !important; padding: 0px !important;" width="1" /> when you wanted to play with it - he's got bigger things to worry about than you two fighting, and he might finish off loading the dishwasher and putting on the laundry before settling the argument. &nbsp;If you draw attention to yourself with a lock, not only does it take time to get the operating system to arbitrate, the OS might decide the CPU has better things to do than servicing your thread.<br /><br />The Disruptor paper talks about an experiment we did. &nbsp;The test calls a function incrementing a 64-bit counter in a loop 500 million times. &nbsp;For a single thread with no locking, the test takes 300ms. &nbsp;If you add a lock (and this is for a single thread, no contention, and no additional complexity other than the lock) the test takes&nbsp;10,000ms. &nbsp;That's, like, two orders of magnitude slower. &nbsp;Even more astounding, if you add a second thread (which logic suggests should take maybe half the time of the single thread with a lock) it takes&nbsp;224,000ms. &nbsp;Incrementing a counter 500 million times takes nearly a <i>thousand </i>times longer when you split it over two threads instead of running it on one with no lock.<br /><br /><b>Concurrency Is Hard and Locks Are Bad</b><br />I'm just touching the surface of the problem, and obviously I'm using very simple examples. &nbsp;But the point is, if your code is meant to work in a multi-threaded environment, your job as a developer just got a lot more difficult:<br /><ul><li><b>Naive code can have unintended consequences.</b>&nbsp; Case Three above is an example of how things can go horribly wrong if you don't realise you have multiple threads accessing and writing to the same data.</li><li><b>Selfish code is going to slow your system down.</b>&nbsp; Using locks to protect your code from the problem in Case Three can lead to things like deadlock or simply poor performance.</li></ul>This is why many organisations have some sort of concurrency problems in their interview process (certainly for Java interviews). &nbsp;Unfortunately it's very easy to learn how to answer the questions without really understanding the problem, or possible solutions to it.<br /><br /><b>How does the Disruptor address these issues?</b><br />For a start, it doesn't use locks. &nbsp;At all.<br /><br />Instead, where we need to make sure that operations are thread-safe (specifically, updating the next available sequence number in the case of <a href="http://mechanitis.blogspot.com/2011/07/dissecting-disruptor-writing-to-ring.html">multiple producers</a>), we use a <a href="http://en.wikipedia.org/wiki/Compare-and-swap">CAS </a>(Compare And Swap/Set) operation. &nbsp;This is a CPU-level instruction, and in my mind it works a bit like optimistic locking - the CPU goes to update a value, but if the value it's changing it from is not the one it expects, the operation fails because clearly something else got in there first.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-j7wPAJe3YuE/TiFBp0XCn6I/AAAAAAAAIIM/FrketUYEsFY/s1600/ConcurrencyCAS.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="170" src="http://4.bp.blogspot.com/-j7wPAJe3YuE/TiFBp0XCn6I/AAAAAAAAIIM/FrketUYEsFY/s320/ConcurrencyCAS.png" width="320" /></a></div><br />Note this could be two different cores rather than two separate CPUs.<br /><br />CAS operations are much cheaper than locks because they don't involve the operating system, they go straight to the CPU. &nbsp;But they're not cost-free - in the experiment I mentioned above, where a lock-free thread takes 300ms and a thread with a lock takes 10,000ms, a single thread using CAS takes 5,700ms. &nbsp;So it takes less time than using a lock, but more time than a single thread that doesn't worry about contention at all.<br /><br />Back to the Disruptor - I talked about the <a href="http://code.google.com/p/disruptor/source/browse/trunk/code/src/main/com/lmax/disruptor/ClaimStrategy.java">ClaimStrategy</a> when I <a href="http://mechanitis.blogspot.com/2011/07/dissecting-disruptor-writing-to-ring.html">went over the producers</a>. &nbsp;In the code you'll see two strategies, a <code>SingleThreadedStrategy</code> and a <code>MultiThreadedStrategy</code>. &nbsp;You could argue, why not just use the multi-threaded one with only a single producer? &nbsp;Surely it can handle that case? &nbsp;And it can. &nbsp;But the multi-threaded one uses an <a href="http://download.oracle.com/javase/6/docs/api/java/util/concurrent/atomic/AtomicLong.html">AtomicLong</a> (Java's way of providing CAS operations), and the single-threaded one uses a simple long with no locks and no CAS. &nbsp;This means the single-threaded claim strategy is as fast as possible, given that it knows there is only one producer and therefore no contention on the sequence number.<br /><br />I know what you're thinking: turning one single number into an AtomicLong can't possibly have been the only thing that is the secret to the Disruptor's speed. And of course, it's not - otherwise this wouldn't be called "Why it's so fast (part <i>one</i>)".<br /><br />But this is an important point - there's only one place in the code where multiple threads might be trying to update the same value. &nbsp;Only one place in the whole of this complicated data-structure-slash-framework. &nbsp;And that's the secret. &nbsp;Remember everything has its own sequence number? &nbsp;If you only have one producer then every sequence number in the system is only ever written to by one thread. That means there is no contention. &nbsp;No need for locks. &nbsp;No need even for CAS. &nbsp;The only sequence number that is ever written to by more than one thread is the one on the <code>ClaimStrategy</code> if there is more than one producer.<br /><br />This is also why each variable in the <code>Entry</code> <a href="http://mechanitis.blogspot.com/2011/07/dissecting-disruptor-wiring-up.html">can only be written to by one consumer</a>. &nbsp;It ensures there's no write contention, therefore no need for locks or CAS.<br /><br /><b>Back to why queues aren't up to the job</b><br />So you start to see why queues, which may implemented as a ring buffer under the covers, still can't match the performance of the Disruptor. &nbsp;The queue, and the&nbsp;<a href="http://en.wikipedia.org/wiki/Circular_buffer">basic ring buffer</a>, only has two pointers - one to the front of the queue and one to the end:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-9yewqxZu37M/TiGdFiaCj6I/AAAAAAAAIIU/bF4fxONwB_8/s1600/QueueMultiple.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="130" src="http://4.bp.blogspot.com/-9yewqxZu37M/TiGdFiaCj6I/AAAAAAAAIIU/bF4fxONwB_8/s400/QueueMultiple.png" width="400" /></a></div><br />If more than one producer wants to place something on the queue, the tail pointer will be a point of contention as more than one thing wants to write to it. &nbsp;If there's more than one consumer, then the head pointer is contended, because this is not just a read operation but a write, as the pointer is updated when the item is consumed from the queue.<br /><br />But wait, I hear you cry foul! &nbsp;Because we already knew this, so queues are usually single producer and single consumer (or at least they are in all the queue comparisons in our performance tests).<br /><br />There's another thing to bear in mind with queues/buffers. &nbsp;The whole point is to provide a place for things to hang out between producers and consumers, to help buffer bursts of messages from one to the other. &nbsp;This means the buffer is usually full (the producer is out-pacing the consumer) or empty (the consumer is out-pacing the producer). &nbsp;It's rare that the producer and consumer will be so evenly-matched that the buffer has items in it but the producers and consumers are keeping pace with each other.<br /><br />So this is how things really look. &nbsp;An empty queue:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-_-lU_Ey7mi4/TiGmx5Ja2jI/AAAAAAAAIIg/gQOZ8f76mLM/s1600/QueueEmpty.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="173" src="http://1.bp.blogspot.com/-_-lU_Ey7mi4/TiGmx5Ja2jI/AAAAAAAAIIg/gQOZ8f76mLM/s400/QueueEmpty.png" width="400" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"></div><br />...and a full queue:<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-ARPMAbYKnoE/TiGm4hgxeDI/AAAAAAAAIIk/xMl4ItVob2U/s1600/QueueFull.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="178" src="http://3.bp.blogspot.com/-ARPMAbYKnoE/TiGm4hgxeDI/AAAAAAAAIIk/xMl4ItVob2U/s400/QueueFull.png" width="400" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"></div>The queue needs a size so that it can tell the difference between empty and full. &nbsp;Or, if it doesn't, it might determine that based on the contents of that entry, in which case reading an entry will require a write to erase it or mark it as consumed. <br /><br />Whichever implementation is chosen, there's quite a bit of contention around the tail, head and size variables, or the entry itself if a consume operation also includes a write to remove it.<br /><br />On top of this, these three variables are often in the same <a href="http://en.wikipedia.org/wiki/CPU_cache">cache line</a>, leading to <a href="http://en.wikipedia.org/wiki/False_sharing">false sharing</a>. &nbsp;So, not only do you have to worry about the producer and the consumer both causing a write to the size variable (or the entry), updating the tail pointer could lead to a cache-miss when the head pointer is updated because they're sat in the same place. &nbsp;I'm going to duck out of going into that in detail because this post is quite long enough as it is.<br /><br />So this is what we mean when we talk about "Teasing Apart the Concerns" or a queue's "conflated concerns". &nbsp;By giving everything its own sequence number and by allowing only one consumer to write to each variable in the <code>Entry</code>, the only case the Disruptor needs to manage contention is where more than one producer is writing to the ring buffer.<br /><br /><b>In summary</b><br />The Disruptor a number of advantages over traditional approaches:<br /><ol><li>No contention = no locks = it's very fast.</li><li>Having everything track its own sequence number allows multiple producers and multiple consumers to use the same data structure.</li><li>Tracking sequence numbers at each individual place (ring buffer, claim strategy, producers and consumers), plus the <a href="http://code.google.com/p/disruptor/source/browse/trunk/code/src/main/com/lmax/disruptor/RingBuffer.java">magic cache line padding</a>, means no false sharing and no unexpected contention.</li></ol><div>EDIT: Note that version 2.0 of the Disruptor uses different names to the ones in this article. &nbsp;Please see <a href="http://mechanitis.blogspot.com/2011/08/disruptor-20-all-change-please.html">my summary of the changes</a> if you are confused about class names.</div></div>
